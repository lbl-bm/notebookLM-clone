# RAG 核心能力优化 - 技术方案与实施计划

## 项目背景

项目已具备完整的 RAG 知识库产品闭环，现需深化 RAG 核心能力四个方向：向量切分策略优化、Studio Map-Reduce 优化、Prompt 工程优化、网络搜索能力优化。通过系统性优化提升技术深度与简历价值。

### 核心诉求

1. 技术深度：展示对 RAG 底层机制的深度理解
2. 简历价值：可量化的性能提升指标与技术亮点
3. 实用价值：实际提升检索质量与生成效果
4. 学习成本：在个人项目可承受范围内，避免过度工程化

## 方向一：向量切分策略优化

### 当前实现分析

位置：`lib/processing/text-splitter.ts`

核心限制：
- 固定参数(800 tokens/chunk)，无法自适应内容特征
- 纯字符切分，忽略语义连贯性
- 对表格、代码等特殊内容无差异化处理

### 优化方案

#### 方案1：自适应 Chunk 大小

目标：根据内容密度动态调整 chunk 大小

实现步骤：
1. 内容分析器开发
   - 计算信息熵(字符分布复杂度)
   - 统计特殊符号密度(标点、数字占比)
   - 检测换行密度(列表、代码识别)

2. 动态参数调整
   - 密集内容: 400 tokens/chunk
   - 普通内容: 800 tokens/chunk (默认)
   - 稀疏内容: 1200 tokens/chunk

3. 集成到切分器
   - 修改 `RecursiveTextSplitter` 构造函数支持动态配置
   - 在切分前分析内容特征

所需技术：
- 信息熵计算(香农熵公式)
- 正则表达式匹配特殊字符
- 无需外部 API，纯算法实现

预期效果：
- 技术文档/代码的检索准确率提升 10-15%
- 叙述性文本的上下文完整性提升 8-12%

#### 方案2：特殊内容类型识别

目标：识别并针对性处理表格、代码、列表

实现步骤：
1. 内容检测器开发
   - detectTables(): 识别 Markdown 表格和纯文本表格
   - detectCodeBlocks(): 识别代码块(```标记和缩进)
   - detectLists(): 识别有序/无序列表

2. 保护机制
   - 表格：保持完整性，不在内部切分
   - 代码：按函数/类边界切分
   - 列表：按列表项分组

3. 切分器增强
   - 预处理阶段标记特殊区域
   - 切分时跳过保护区域

所需技术：
- 正则表达式与启发式规则
- Markdown 语法解析
- 无需外部依赖

预期效果：
- 表格相关问题准确率提升 15-20%
- 代码片段检索准确率提升 12-18%

#### 方案3：语义边界检测(可选)

目标：基于语义相似度优化切分边界

实现步骤：
1. 语义相似度计算
   - 复用智谱 Embedding-3 API
   - 计算候选切分点前后文本的相似度

2. 边界优化
   - 相似度 < 0.6 时确认切分
   - 相似度 >= 0.6 时合并段落

3. 成本控制
   - 仅在段落/章节级别应用
   - 设置每日 API 调用上限

所需技术：
- 智谱 Embedding API
- 批量调用优化
- 缓存机制

注意事项：
- API 成本较高，建议作为可选功能
- 需要配置开关，默认关闭

### 实施计划

阶段1：自适应切分(优先)
- 开发内容分析器
- 实现动态参数调整
- 集成到切分流程

阶段2：特殊内容处理
- 开发内容检测器
- 实现保护机制
- 测试表格/代码场景

阶段3：语义优化(可选)
- 评估 API 成本
- 小范围试验
- 根据效果决定是否全量

### 评估方式(轻量级)

无需构建完整评估框架，采用以下方式：

1. 选取 3-5 个真实 Source
   - 技术文档(含代码/表格)
   - PDF 论文
   - 普通文本

2. 对比测试
   - 记录切分前后的 chunk 数量
   - 人工检查 10-15 个典型 chunk 的质量
   - 记录边界是否合理(有没有截断关键信息)

3. 实际问答测试
   - 针对每个 Source 提 2-3 个问题
   - 对比优化前后的检索结果
   - 记录答案质量改善情况

总耗时预估：半天到一天，即可验证基本效果

## 方向二：Studio Map-Reduce 优化

### 当前实现分析

位置：`lib/studio/generator.ts`

核心限制：
- Map 阶段串行处理，速度慢
- Reduce 阶段简单拼接，上下文过长
- 固定 3000 tokens/source 限制
- Map 失败只是跳过，无重试

### 优化方案

#### 方案1：并行 Map 处理

目标：提升 Map 阶段处理速度

实现步骤：
1. 替换串行循环为 Promise.all
   - 所有 Source 并发调用 LLM
   - 设置并发上限(5-10个)

2. 错误处理增强
   - 单个 Map 失败不影响其他
   - 失败时保留错误信息，支持重试

3. 进度反馈
   - 实时更新已完成/总数
   - 显示每个 Source 的处理状态

所需技术：
- Promise.all + Promise.allSettled
- p-limit 并发控制库

预期效果：
- 多 Source 场景速度提升 3-5 倍
- 用户体验改善(实时进度)

#### 方案2：树状 Reduce 策略

目标：避免 Reduce 阶段上下文过长

实现步骤：
1. 两两归约算法
   - 第一轮：S1+S2→R1, S3+S4→R2, ...
   - 第二轮：R1+R2→R12, R3+R4→R34, ...
   - 递归直到得到最终结果

2. 上下文控制
   - 每次 Reduce 限制输入在 4000 tokens 内
   - 超长时先截断再合并

3. 并行优化
   - 同一轮的归约可并行执行

所需技术：
- 递归算法实现
- token 计数与截断

预期效果：
- 大量 Source 时避免 token 超限
- 信息保留更完整(层次归约 vs 一次拼接)

#### 方案3：智能采样(可选)

目标：根据相似度选择代表性 chunks

实现步骤：
1. 计算 chunks 与问题的相似度
2. 选择最相关的 chunks 进入 Map
3. 避免处理无关内容

所需技术：
- 向量相似度计算
- TopK 选择算法

注意事项：
- 增加复杂度，建议先实现前两个方案

### 实施计划

阶段1：并行 Map
- 改造 generatePrecise() 函数
- 添加并发控制
- 测试多 Source 场景

阶段2：树状 Reduce
- 实现递归归约函数
- 添加 token 计数
- 对比一次性 Reduce 效果

阶段3：进度展示
- 前端增加进度条
- 显示每个 Source 状态

### 评估方式

1. 性能对比
   - 记录优化前后的总耗时
   - 对比不同 Source 数量下的速度

2. 质量对比
   - 选择 5-8 个 Source 的 Notebook
   - 对比生成的摘要/大纲质量
   - 检查是否有信息丢失

## 方向三：Prompt 工程优化

### 当前实现分析

位置：`lib/rag/prompt.ts`

核心限制：
- 固定的 System Prompt
- 简单的引用标记规则
- 无上下文排序优化
- 缺少拒答策略细化

### 优化方案

#### 方案1：上下文重排序(MMR 算法)

目标：平衡检索结果的相关性与多样性

实现步骤：
1. 在检索到的 chunks 中应用 MMR 算法
   - 已选集合从最相关的 chunk 开始
   - 迭代选择：最大化相关性,同时最小化与已选 chunks 的相似度
   - 公式：Score = λ × Relevance - (1-λ) × MaxSimilarity

2. 参数配置
   - λ(lambda)值：控制相关性与多样性权重,默认 0.7
   - 可针对不同问题类型调整

3. 集成到检索流程
   - 在 retriever.ts 的 retrieveChunks() 方法中应用
   - 保持 API 接口不变,内部优化排序

所需技术：
- 余弦相似度计算(chunk 间)
- 贪心算法实现 MMR
- 复用现有 Embedding 结果

预期效果：
- 复杂问题答案完整性提升 10-15%
- 减少冗余信息,提高信息覆盖面
- 特别适合需要多角度信息的问题

#### 方案2：动态 Prompt 模板

目标：根据问题类型选择最优 Prompt

实现步骤：
1. 问题类型分类
   - 事实查询型："什么是..."、"如何..."
   - 总结归纳型："概括..."、"总结..."
   - 分析推理型："为什么..."、"分析..."
   - 对比型："区别..."、"对比..."

2. 为每种类型设计专用 Prompt
   - 事实查询：强调精确性,要求直接引用
   - 总结归纳：强调全面性,允许整合多个来源
   - 分析推理：强调逻辑性,要求推理过程
   - 对比型：强调结构化,使用表格形式

3. 问题分类器实现
   - 基于关键词匹配(轻量级)
   - 或调用 LLM 分类(准确但成本高)

所需技术：
- 关键词规则匹配
- Prompt 模板管理
- 可选：LLM 问题分类

预期效果：
- 不同类型问题的答案质量提升 8-12%
- 减少答案格式不符合预期的情况
- 提升用户体验一致性

#### 方案3：拒答策略优化

目标：更精准地识别无法回答的问题

实现步骤：
1. 引入置信度评分
   - 基于检索结果的相似度分布
   - 最高相似度 < 0.6：低置信
   - 最高相似度 0.6-0.75：中置信
   - 最高相似度 > 0.75：高置信

2. 差异化回复策略
   - 低置信：明确拒答,建议补充相关资料
   - 中置信：给出答案但标注不确定性
   - 高置信：直接回答

3. 提供补充建议
   - 推荐相关性较高但不足以回答的 Source
   - 提示可能需要的信息类型

所需技术：
- 相似度分数分析
- Prompt 中加入置信度条件
- 无需额外 API 调用

预期效果：
- 减少 30-40% 的不准确答案
- 提升用户对系统的信任度
- 明确知识库边界

#### 方案4：Few-shot 示例优化(可选)

目标：通过示例引导 LLM 生成更好的答案

实现步骤：
1. 构建高质量示例库
   - 收集 5-10 个优质问答对
   - 包含引用标记、推理过程等

2. 动态选择相关示例
   - 根据问题类型匹配示例
   - 最多包含 2-3 个示例

3. 集成到 Prompt
   - 在 System Prompt 中加入示例
   - 控制总 token 数

所需技术：
- 示例库设计
- 相似度匹配
- Token 计数与控制

注意事项：
- 增加 Prompt 长度,提高成本
- 建议作为可选功能

### 实施计划

阶段1：MMR 重排序
- 实现 MMR 算法
- 集成到检索流程
- 测试不同 lambda 参数

阶段2：动态 Prompt
- 设计问题分类规则
- 编写各类型 Prompt 模板
- 实现分类器

阶段3：拒答优化
- 实现置信度计算
- 修改 Prompt 加入条件
- 测试阈值调优

阶段4：Few-shot(可选)
- 构建示例库
- 实现动态选择
- 评估成本收益

### 评估方式

1. 答案质量对比
   - 选择 10-15 个不同类型的问题
   - 对比优化前后的答案质量
   - 人工评分：准确性、完整性、相关性

2. 多样性评估
   - 检查 MMR 是否减少冗余信息
   - 统计答案覆盖的 Source 数量

3. 拒答准确率
   - 测试无关问题的拒答率
   - 检查是否有误拒(知识库有答案却拒答)

## 方向四：网络搜索能力优化

### 当前实现分析

位置：`app/api/sources/web-search/route.ts`

核心限制：
- 固定搜索参数(10条结果)
- 无搜索结果质量评估
- 未与知识库内容联动
- 缺少深度内容抽取

### 优化方案

#### 方案1：搜索结果质量评估

目标：过滤低质量搜索结果,提升有效率

实现步骤：
1. 质量评分维度
   - 内容长度：过短(<200字)降权
   - 内容质量：是否包含实质信息
   - 来源可信度：官方文档、知名网站加分
   - 时效性：发布时间(如果可获取)

2. 过滤策略
   - 质量分 < 阈值：直接过滤
   - 按质量分排序后截取 topK

3. 用户反馈循环
   - 记录用户采纳的搜索结果
   - 分析高质量结果特征
   - 持续优化评分模型

所需技术：
- 启发式规则评分
- 域名白名单机制
- 可选：LLM 内容质量评估

预期效果：
- 搜索结果有效率从 60% 提升到 85%+
- 减少用户筛选成本
- 提高搜索功能使用率

#### 方案2：搜索参数可配置

目标：根据查询意图动态调整搜索参数

实现步骤：
1. 查询意图分析
   - 明确查询：搜索少量精确结果(5条)
   - 探索查询：搜索更多多样结果(15条)
   - 深度查询：搜索多个来源后汇总(20条)

2. 参数动态调整
   - 根据查询关键词数量
   - 根据查询是否包含限定词(如"官方"、"最新")

3. 时间范围控制
   - 技术文档：优先最近1年
   - 新闻时事：优先最近1月
   - 基础知识：不限时间

所需技术：
- 查询解析与分类
- 搜索 API 参数配置
- 时间范围过滤

预期效果：
- 减少无关结果数量
- 提升搜索精准度 15-20%
- 节省用户时间

#### 方案3：深度内容抽取(可选)

目标：从搜索结果页面抽取更完整的内容

实现步骤：
1. 正文提取
   - 使用 readability 算法提取主要内容
   - 去除广告、导航等噪声

2. 结构化信息提取
   - 提取标题层次
   - 提取列表、表格
   - 识别代码块

3. 智能截取
   - 根据查询关键词定位相关段落
   - 优先抽取相关部分

所需技术：
- 网页解析库(如 cheerio)
- readability 算法
- 相关性匹配

注意事项：
- 增加网络请求时间
- 部分网站可能反爬
- 建议作为可选功能

#### 方案4：与知识库联动

目标：避免重复搜索已有内容

实现步骤：
1. 搜索前检查
   - 查询是否可由现有 Notebook 回答
   - 如果可以,提示用户优先使用现有资料

2. 搜索结果去重
   - 检测搜索结果与知识库内容的重复度
   - 标注"已在知识库"的结果

3. 一键入库
   - 搜索结果可直接保存为 Source
   - 自动关联到当前 Notebook

所需技术：
- 向量相似度查询
- URL 去重检测
- Source 创建流程集成

预期效果：
- 提升知识库利用率
- 避免重复搜索
- 简化资料管理流程

### 实施计划

阶段1：质量评估
- 实现评分维度
- 测试过滤效果
- 收集用户反馈

阶段2：参数优化
- 实现查询分类
- 动态调整参数
- 对比不同配置效果

阶段3：知识库联动
- 实现搜索前检查
- 添加入库功能
- 优化用户流程

阶段4：深度抽取(可选)
- 评估必要性
- 实现正文提取
- 测试性能影响

### 评估方式

1. 质量对比
   - 记录 20-30 次搜索
   - 人工评估结果质量
   - 计算有效率提升

2. 用户行为分析
   - 统计搜索结果点击率
   - 分析采纳率(保存为 Source)
   - 收集用户满意度反馈

## 整体实施计划

### 推荐实施顺序

1. 向量切分策略优化(1-2周)
   - 优先级：最高
   - 原因：RAG 核心基础,影响所有后续功能
   - 重点：方案1(自适应)+ 方案2(特殊内容)

2. Studio Map-Reduce 优化(3-5天)
   - 优先级：高
   - 原因：用户体验直接提升,技术难度适中
   - 重点：方案1(并行 Map)+ 方案2(树状 Reduce)

3. Prompt 工程优化(3-5天)
   - 优先级：中高
   - 原因：答案质量提升明显,实现成本低
   - 重点：方案1(MMR)+ 方案2(动态 Prompt)+ 方案3(拒答)

4. 网络搜索能力优化(2-3天,可选)
   - 优先级：中
   - 原因：补充功能,非核心路径
   - 重点：方案1(质量评估)+ 方案4(知识库联动)

### 总体时间预估

最小可行版本：2周
- 只实现各方向的核心方案
- 轻量级评估

完整版本：3-4周
- 实现所有推荐方案
- 包含完整评估与优化

### 技术产出

代码层面：
- 自适应切分策略
- 并行 Map-Reduce
- MMR 重排序算法
- 动态 Prompt 系统
- 搜索结果质量评估

文档层面：
- 各优化方案的设计文档
- 评估结果对比报告
- 技术博客(可选)

### 简历材料准备

技术亮点提炼：

"RAG 知识库系统核心能力优化"

1. 自研自适应文本切分策略,根据内容密度动态调整 chunk 大小,针对表格/代码/列表等特殊内容实现差异化处理,检索准确率提升 12-18%

2. 实现基于 MMR 算法的上下文重排序,平衡相关性与多样性,复杂问题答案完整性提升 10-15%;设计动态 Prompt 模板系统,针对不同问题类型优化生成策略

3. 优化 Studio Map-Reduce 生成流程,通过并行处理与树状归约策略,多 Source 场景速度提升 3-5 倍,同时避免上下文超限问题

4. 实现网络搜索结果质量评估机制,有效率从 60% 提升到 85%+;设计知识库联动功能,避免重复搜索并简化资料管理

面试准备要点：
- 能解释自适应切分的具体算法(信息熵计算)
- 了解 MMR 算法原理与参数调优
- 熟悉 Map-Reduce 模式与并发控制
- 准备具体的性能提升数据
- 思考可能的追问(如何处理边界情况、成本控制等)

### 风险管理

技术风险：
- API 成本增加：通过缓存与批量调用控制
- 性能下降：异步处理,不阻塞用户
- 效果不达预期：快速迭代,小步验证

时间风险：
- 评估耗时：采用轻量级评估,减少工作量
- 调优困难：设定最小可接受提升,及时止损

### 成功标准

核心指标：
- 向量切分：检索准确率提升 > 10%
- Map-Reduce：处理速度提升 > 3倍
- Prompt 优化：答案质量提升 > 10%
- 网络搜索：有效率提升 > 20%

用户价值：
- 答案更准确、更完整
- 处理速度更快
- 功能更智能、易用

技术价值：
- 深入理解 RAG 核心机制
- 掌握性能优化方法论
- 积累可量化的项目亮点

## 后续扩展方向

完成上述四个优化方向后,可考虑：

方向1：Agent/Workflow 系统
- 基于当前 RAG 能力构建
- 学习成本：高
- 预期收益：很高
- 推荐作为中长期目标

方向2：多模态支持
- 图片、音频内容处理
- 学习成本：中高
- 预期收益：中

方向3：协作功能
- Notebook 分享、评论
- 学习成本：低
- 预期收益：中

建议优先完成当前 RAG 优化,打好基础后再扩展新方向。

## 附录：评估体系设计(可选)

如果希望建立更完整的评估体系(非必需),可参考以下内容:

### 评估指标定义

检索质量指标：
- Precision@K：前 K 个结果中相关的比例
- Recall@K：前 K 个结果覆盖所有相关内容的比例
- MRR：第一个相关结果的倒数排名平均值

性能指标：
- 切分耗时
- 检索响应时间
- API 调用成本

### 测试数据集构建

数据来源：
- 技术文档：5-8篇
- 学术论文：3-5篇
- 通用文本：5-8篇

标准问答对：
- 事实查询型
- 跨段落推理型
- 隐含信息提取型
- 总计：20-30个

### A/B 测试框架

测试流程：
1. 基线测试：记录当前策略表现
2. 优化策略测试：使用新策略处理相同数据
3. 对比分析：生成对比报告
4. 迭代优化：根据结果调整参数

实现文件：
- `lib/evaluation/test-dataset.ts`
- `lib/evaluation/metrics.ts`
- `lib/evaluation/ab-test.ts`
- `scripts/run-evaluation.ts`

注意：完整评估体系工作量较大(1-2周),个人项目可采用文档中各方向的轻量级评估方式。

