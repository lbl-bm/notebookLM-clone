# 项目规划书

<cite>
**本文档引用的文件**
- [README.md](file://README.md)
- [IMPLEMENTATION.md](file://IMPLEMENTATION.md)
- [package.json](file://package.json)
- [next.config.js](file://next.config.js)
- [middleware.ts](file://middleware.ts)
- [lib/config.ts](file://lib/config.ts)
- [lib/db/vector-store.ts](file://lib/db/vector-store.ts)
- [lib/rag/retriever.ts](file://lib/rag/retriever.ts)
- [lib/studio/generator.ts](file://lib/studio/generator.ts)
- [lib/processing/processor.ts](file://lib/processing/processor.ts)
- [lib/processing/text-splitter.ts](file://lib/processing/text-splitter.ts)
- [lib/processing/embedding.ts](file://lib/processing/embedding.ts)
- [lib/rag/prompt.ts](file://lib/rag/prompt.ts)
- [components/notebook/notebook-content.tsx](file://components/notebook/notebook-content.tsx)
- [app/page.tsx](file://app/page.tsx)
</cite>

## 目录
1. [项目概述](#项目概述)
2. [技术架构](#技术架构)
3. [核心模块分析](#核心模块分析)
4. [数据流架构](#数据流架构)
5. [处理队列与工作流](#处理队列与工作流)
6. [RAG 检索系统](#rag-检索系统)
7. [Studio 产物生成](#studio-产物生成)
8. [前端组件架构](#前端组件架构)
9. [性能优化策略](#性能优化策略)
10. [安全与权限控制](#安全与权限控制)
11. [部署与运维](#部署与运维)
12. [未来发展规划](#未来发展规划)

## 项目概述

Personal NotebookLM 是一个基于 RAG（检索增强生成）技术的个人知识库管理系统，旨在为用户提供智能化的知识管理体验。该项目实现了类似 NotebookLM 的核心功能，支持多种知识源导入、向量化处理、智能问答和结构化产物生成。

### 核心功能特性

- **多源知识导入**：支持 PDF 文件、网页链接、文本内容等多种格式的知识源
- **智能向量化处理**：自动解析、切分、嵌入和索引文档内容
- **RAG 问答系统**：基于证据的智能问答，支持引用溯源
- **结构化产物生成**：一键生成测验、思维导图等结构化内容
- **混合检索机制**：结合向量相似度和全文检索，提升检索准确性

### 技术栈概览

- **前端框架**：Next.js 14 + React 18 + TypeScript
- **UI 组件库**：Tailwind CSS + shadcn/ui + Radix UI
- **后端服务**：Node.js + Prisma ORM
- **数据库**：PostgreSQL + pgvector 向量扩展
- **存储服务**：Supabase Storage
- **AI 模型**：智谱 AI + LongCat 推理模型

## 技术架构

### 系统架构图

```mermaid
graph TB
subgraph "前端层"
UI[Next.js 应用]
Components[React 组件]
Hooks[自定义 Hooks]
end
subgraph "API 层"
API_Routes[API 路由]
Auth[认证中间件]
end
subgraph "业务逻辑层"
Processing[文档处理]
RAG[RAG 检索]
Studio[产物生成]
Queue[处理队列]
end
subgraph "数据层"
VectorDB[pgvector 向量库]
SupabaseDB[Supabase PostgreSQL]
Storage[Supabase Storage]
end
subgraph "AI 服务"
Zhipu[智谱 AI]
LongCat[LongCat 模型]
end
UI --> API_Routes
Components --> API_Routes
Hooks --> API_Routes
API_Routes --> Processing
API_Routes --> RAG
API_Routes --> Studio
API_Routes --> Queue
Processing --> VectorDB
RAG --> VectorDB
Studio --> Zhipu
Studio --> LongCat
Processing --> Storage
API_Routes --> SupabaseDB
Auth --> API_Routes
```

**架构图来源**
- [lib/config.ts](file://lib/config.ts#L1-L187)
- [lib/db/vector-store.ts](file://lib/db/vector-store.ts#L1-L446)
- [lib/processing/processor.ts](file://lib/processing/processor.ts#L1-L560)

### 数据库架构

```mermaid
erDiagram
NOTEBOOK {
uuid id PK
string title
uuid user_id
datetime created_at
datetime updated_at
}
SOURCE {
uuid id PK
uuid notebook_id FK
string title
string type
string status
string storage_path
string url
jsonb meta
datetime created_at
datetime updated_at
}
MESSAGE {
uuid id PK
uuid notebook_id FK
string role
string content
jsonb metadata
datetime created_at
}
ARTIFACT {
uuid id PK
uuid notebook_id FK
string type
string content
string status
jsonb meta
datetime created_at
}
DOCUMENT_CHUNKS {
uuid id PK
uuid notebook_id FK
uuid source_id FK
integer chunk_index
string content
string content_hash
jsonb metadata
vector embedding
string embedding_model
integer embedding_dim
tsv content_tsv
datetime created_at
}
PROCESSING_QUEUE {
uuid id PK
uuid source_id FK
integer priority
integer attempts
string status
datetime queued_at
datetime processed_at
}
NOTEBOOK ||--o{ SOURCE : contains
NOTEBOOK ||--o{ MESSAGE : has
NOTEBOOK ||--o{ ARTIFACT : generates
SOURCE ||--o{ DOCUMENT_CHUNKS : creates
SOURCE ||--o{ PROCESSING_QUEUE : queued_in
```

**图表来源**
- [lib/db/vector-store.ts](file://lib/db/vector-store.ts#L1-L446)

## 核心模块分析

### 配置管理系统

配置系统采用集中式管理方式，确保各模块间的配置一致性：

```mermaid
classDiagram
class ConfigManager {
+EMBEDDING_DIM : number
+supabaseConfig : SupabaseConfig
+longcatConfig : LongCatConfig
+zhipuConfig : ZhipuConfig
+validateEnv() : void
+getModelConfig(modelId : string) : ModelConfig
+getStudioModelConfig() : StudioConfig
}
class ModelConfig {
+id : string
+provider : ModelProvider
+model : string
+displayName : string
+description : string
+icon : IconType
}
class SupabaseConfig {
+url : string
+anonKey : string
+secretKey : string
}
class LongCatConfig {
+apiKey : string
+baseUrl : string
+chatModel : string
}
class ZhipuConfig {
+apiKey : string
+baseUrl : string
+embeddingModel : string
+chatModel : string
}
ConfigManager --> ModelConfig : "返回"
ConfigManager --> SupabaseConfig : "包含"
ConfigManager --> LongCatConfig : "包含"
ConfigManager --> ZhipuConfig : "包含"
```

**类图来源**
- [lib/config.ts](file://lib/config.ts#L1-L187)

**配置模块特性**：
- 向量维度强制校验（1024维）
- 多模型提供商支持（智谱、LongCat）
- 环境变量验证机制
- 类型安全的配置访问

### 向量存储系统

向量存储系统是整个 RAG 系统的核心基础设施：

```mermaid
classDiagram
class VectorStore {
<<interface>>
+addDocuments(params) : Promise~number~
+similaritySearch(params) : Promise~RetrievalResult~
+hybridSearch(params) : Promise~HybridResult~
+deleteDocuments(sourceId) : Promise~void~
+getExistingHashes(sourceId) : Promise~Set~string~~
}
class PrismaVectorStore {
-BATCH_INSERT_SIZE : number
+addDocuments(params) : Promise~number~
+similaritySearch(params) : Promise~RetrievalResult~
+hybridSearch(params) : Promise~HybridResult~
+deleteDocuments(sourceId) : Promise~void~
+getExistingHashes(sourceId) : Promise~Set~string~~
}
class ChunkMetadata {
+page : number
+startChar : number
+endChar : number
+tokenCount : number
+chunkStrategy : string
+adaptiveReason : string
+contentAnalysis : ContentAnalysis
}
VectorStore <|-- PrismaVectorStore : "实现"
PrismaVectorStore --> ChunkMetadata : "使用"
```

**类图来源**
- [lib/db/vector-store.ts](file://lib/db/vector-store.ts#L24-L75)

**向量存储特性**：
- 批量插入优化（每批500条）
- 维度一致性校验
- 混合检索支持（向量+全文）
- 去重机制（基于内容哈希）

## 数据流架构

### 文档处理流水线

```mermaid
flowchart TD
Start([开始处理]) --> DetectType{检测源类型}
DetectType --> |PDF文件| PDFFlow["PDF处理流程"]
DetectType --> |网页URL| URLFlow["URL处理流程"]
DetectType --> |文本内容| TextFlow["文本处理流程"]
PDFFlow --> DownloadPDF["下载PDF文件"]
DownloadPDF --> ParsePDF["解析PDF内容"]
ParsePDF --> TextSplit["文本切分"]
TextSplit --> GenerateEmbeddings["生成向量"]
GenerateEmbeddings --> InsertDB["写入数据库"]
URLFlow --> FetchContent["抓取网页内容"]
FetchContent --> DetectType2{检测内容类型}
DetectType2 --> |PDF链接| DownloadPDF2["下载PDF并解析"]
DetectType2 --> |普通网页| ParseWeb["解析网页内容"]
DownloadPDF2 --> TextSplit2["文本切分"]
ParseWeb --> TextSplit2
TextSplit2 --> GenerateEmbeddings2["生成向量"]
GenerateEmbeddings2 --> InsertDB2["写入数据库"]
TextFlow --> SkipDownload["跳过下载"]
SkipDownload --> TextSplit3["文本切分"]
TextSplit3 --> GenerateEmbeddings3["生成向量"]
GenerateEmbeddings3 --> InsertDB3["写入数据库"]
InsertDB --> Ready[状态: ready]
InsertDB2 --> Ready
InsertDB3 --> Ready
Ready --> End([处理完成])
```

**流程图来源**
- [lib/processing/processor.ts](file://lib/processing/processor.ts#L82-L526)

### RAG 检索流程

```mermaid
sequenceDiagram
participant User as 用户
participant API as API层
participant RAG as RAG检索
participant Vector as 向量存储
participant Embed as 嵌入模型
participant LLM as 大语言模型
User->>API : 发送查询请求
API->>RAG : 处理查询参数
RAG->>Embed : 生成查询向量
Embed-->>RAG : 返回查询向量
RAG->>Vector : 向量相似度搜索
Vector-->>RAG : 返回候选片段
RAG->>RAG : MMR重排序
RAG->>API : 返回检索结果
API->>LLM : 组装提示词
LLM-->>API : 返回答案
API-->>User : 返回最终答案
Note over RAG,Vector : 混合检索支持
RAG->>Vector : 全文检索
Vector-->>RAG : 返回FTS结果
RAG->>RAG : 向量+FTS融合
```

**序列图来源**
- [lib/rag/retriever.ts](file://lib/rag/retriever.ts#L57-L139)
- [lib/rag/prompt.ts](file://lib/rag/prompt.ts#L217-L257)

## 处理队列与工作流

### 处理队列架构

```mermaid
graph LR
subgraph "队列管理"
Queue[ProcessingQueue]
Worker[Worker进程]
Cron[Cron调度器]
end
subgraph "状态流转"
Pending[pending]
Processing[processing]
Ready[ready]
Failed[failed]
end
subgraph "监控机制"
Metrics[性能指标]
Logs[处理日志]
Alerts[告警通知]
end
Queue --> Worker
Worker --> Cron
Cron --> Queue
Queue --> Pending
Pending --> Processing
Processing --> Ready
Processing --> Failed
Worker --> Metrics
Worker --> Logs
Worker --> Alerts
```

**架构图来源**
- [lib/processing/processor.ts](file://lib/processing/processor.ts#L56-L77)

### 队列处理策略

| 队列状态 | 描述 | 处理策略 |
|---------|------|----------|
| pending | 等待处理 | 高优先级队列，优先处理新加入的源 |
| processing | 正在处理 | 分批处理，支持并发控制 |
| ready | 处理完成 | 可供检索使用 |
| failed | 处理失败 | 重试机制，最多3次重试 |

## RAG 检索系统

### 检索算法优化

```mermaid
flowchart TD
Query[用户查询] --> Analyze[内容分析]
Analyze --> Classify[问题类型分类]
Classify --> SelectPrompt[选择系统提示词]
Query --> Embedding[生成查询向量]
Embedding --> VectorSearch[向量相似度搜索]
VectorSearch --> FTS[全文检索]
FTS --> Hybrid[混合检索]
Hybrid --> MMR[MMR重排序]
MMR --> Dedup[去重处理]
Dedup --> Context[构建上下文]
SelectPrompt --> Context
Context --> Messages[组装消息列表]
Messages --> Answer[生成答案]
```

**流程图来源**
- [lib/rag/retriever.ts](file://lib/rag/retriever.ts#L234-L357)
- [lib/rag/prompt.ts](file://lib/rag/prompt.ts#L111-L157)

### 检索性能优化

| 优化策略 | 实现方式 | 性能提升 |
|---------|----------|----------|
| MMR重排序 | 平衡相关性和多样性 | 提升答案质量 |
| 候选集限制 | 最多20个候选进行重排序 | 减少计算开销 |
| 维度校验 | 运行时向量维度检查 | 防止数据不一致 |
| 批量处理 | 向量存储批量插入 | 提升写入性能 |

## Studio 产物生成

### 生成策略对比

```mermaid
graph TB
subgraph "快速模式 (fast)"
FastStart[开始] --> SmartSampling[智能采样]
SmartSampling --> CallLLM[调用LLM]
CallLLM --> ParseResult[解析结果]
ParseResult --> FastEnd[结束]
end
subgraph "精准模式 (precise)"
PreciseStart[开始] --> MapPhase[Map阶段]
MapPhase --> ParallelProcess[并行处理]
ParallelProcess --> ReducePhase[Reduce阶段]
ReducePhase --> TreeReduce[树状归约]
TreeReduce --> ParseResult2[解析结果]
ParseResult2 --> PreciseEnd[结束]
end
FastStart -.->|适合简单查询| MapPhase
PreciseStart -.->|适合复杂分析| SmartSampling
```

**架构图来源**
- [lib/studio/generator.ts](file://lib/studio/generator.ts#L124-L173)
- [lib/studio/generator.ts](file://lib/studio/generator.ts#L366-L448)

### 并发控制机制

| 组件 | 并发限制 | 重试机制 | 超时设置 |
|------|----------|----------|----------|
| Map阶段 | 8个并发 | 最多重试2次 | 45秒 |
| Reduce阶段 | 无限制 | 指数退避 | 180秒 |
| LLM调用 | 无限制 | 超时控制 | 90-180秒 |
| 源处理 | p-limit控制 | 失败重试 | 10-60秒 |

## 前端组件架构

### Notebook 三栏布局

```mermaid
graph LR
subgraph "Notebook容器"
Container[NotebookContent]
end
subgraph "左侧栏 - Sources"
SourceSidebar[SourceSidebar]
SourceList[SourceList]
SourceUploader[SourceUploader]
end
subgraph "中间栏 - Chat"
ChatPanel[ChatPanel]
MessageList[MessageList]
InputArea[InputArea]
end
subgraph "右侧栏 - Studio"
StudioPanel[StudioPanel]
TemplateLibrary[TemplateLibrary]
ArtifactViewer[ArtifactViewer]
end
Container --> SourceSidebar
Container --> ChatPanel
Container --> StudioPanel
SourceSidebar --> SourceList
SourceSidebar --> SourceUploader
ChatPanel --> MessageList
ChatPanel --> InputArea
StudioPanel --> TemplateLibrary
StudioPanel --> ArtifactViewer
```

**架构图来源**
- [components/notebook/notebook-content.tsx](file://components/notebook/notebook-content.tsx#L71-L127)

### 组件通信模式

```mermaid
sequenceDiagram
participant Parent as NotebookContent
participant Sidebar as SourceSidebar
participant Chat as ChatPanel
participant Studio as StudioPanel
Parent->>Sidebar : 传递notebookId和sources
Parent->>Chat : 传递initialMessages
Parent->>Studio : 传递readySourceCount
Sidebar->>Parent : 源状态变化事件
Chat->>Parent : 消息更新事件
Studio->>Parent : 产物生成事件
Parent->>Parent : 状态更新和重新渲染
```

**序列图来源**
- [components/notebook/notebook-content.tsx](file://components/notebook/notebook-content.tsx#L77-L83)

## 性能优化策略

### 向量切分策略优化

项目实现了自适应向量切分策略，根据不同内容密度动态调整切分参数：

| 内容类型 | 密度特征 | 推荐切分大小 | 重叠比例 |
|----------|----------|-------------|----------|
| 高密度内容 | 信息熵>4.5<br/>符号密度>15%<br/>换行密度>3<br/>代码/表格 | 400 tokens | 15% |
| 中等密度内容 | 默认配置 | 800 tokens | 12.5% |
| 低密度内容 | 信息熵<3.5<br/>符号密度<5%<br/>换行密度<1 | 1200 tokens | 10% |

### 批量处理优化

```mermaid
flowchart TD
BatchStart[开始批量处理] --> SplitBatch[分割批次]
SplitBatch --> ProcessBatch[处理批次]
ProcessBatch --> CheckResult{处理完成?}
CheckResult --> |否| SplitBatch
CheckResult --> |是| MergeResult[合并结果]
MergeResult --> Optimize[性能优化]
Optimize --> BatchEnd[批量处理完成]
```

**优化策略**：
- 批量插入大小：500条/批
- 并发控制：p-limit限制
- 重试机制：指数退避
- 去重优化：基于内容哈希

## 安全与权限控制

### 路由保护机制

```mermaid
flowchart TD
Request[HTTP请求] --> CheckAuth{检查认证}
CheckAuth --> |未认证| RedirectLogin[重定向到登录页]
CheckAuth --> |已认证| CheckRoute{检查路由权限}
CheckRoute --> |受保护路由且未登录| RedirectLogin
CheckRoute --> |受保护路由且已登录| AllowAccess[允许访问]
CheckRoute --> |公开路由| AllowAccess
CheckRoute --> |登录路由且已登录| RedirectNotebooks[重定向到笔记本页]
CheckRoute --> |登录路由且未登录| AllowAccess
RedirectLogin --> End[结束]
RedirectNotebooks --> End
AllowAccess --> End
```

**安全机制**：
- 中间件级别的路由保护
- 会话状态管理
- 自动重定向逻辑
- Cookie同步机制

### 数据访问控制

| 数据类型 | 访问控制 | 安全措施 |
|----------|----------|----------|
| 用户数据 | 基于用户ID的隔离 | Supabase Row Level Security |
| 存储文件 | 基于用户权限的访问 | Supabase Storage ACL |
| 向量数据 | 笔记本级别的隔离 | 笔记本ID约束 |
| API访问 | Bearer Token认证 | CRON_SECRET鉴权 |

## 部署与运维

### 环境配置

项目支持多种部署环境，包括开发、测试和生产环境：

```mermaid
graph TB
subgraph "开发环境"
Dev[localhost:3000]
DevDB[本地数据库]
DevStorage[本地存储]
end
subgraph "生产环境"
Prod[Supabase托管]
ProdDB[Supabase Postgres]
ProdStorage[Supabase Storage]
ProdVector[pgvector扩展]
end
subgraph "CI/CD流程"
Build[构建]
Test[测试]
Deploy[部署]
Monitor[监控]
end
Dev --> Build
Prod --> Build
Build --> Test
Test --> Deploy
Deploy --> Monitor
```

### 性能监控

| 监控指标 | 收集方式 | 阈值设置 |
|----------|----------|----------|
| 向量插入延迟 | 日志记录 | <500ms |
| 检索响应时间 | 性能统计 | <2s |
| LLM调用成功率 | 错误日志 | >95% |
| 处理队列积压 | 队列监控 | <10个任务 |

## 未来发展规划

### 短期目标（1-3个月）

1. **性能优化**
   - 实现向量检索的近似最近邻算法
   - 优化数据库索引策略
   - 增加缓存层减少重复计算

2. **功能扩展**
   - 支持更多文件格式（Word、Excel等）
   - 实现批量导入功能
   - 增加数据导出功能

3. **用户体验改进**
   - 优化移动端适配
   - 增加主题切换功能
   - 改进错误处理和提示

### 中期目标（3-6个月）

1. **AI能力增强**
   - 集成更多模型提供商
   - 实现多模态内容处理
   - 支持自定义提示词模板

2. **协作功能**
   - 实现笔记本共享功能
   - 增加评论和标注系统
   - 支持版本管理和历史记录

3. **企业级功能**
   - 增加权限管理
   - 实现审计日志
   - 支持组织架构管理

### 长期愿景（6-12个月）

1. **平台化发展**
   - 构建开发者API
   - 实现插件生态系统
   - 支持第三方集成

2. **技术创新**
   - 探索新的检索算法
   - 实现增量学习能力
   - 支持多语言处理

3. **生态建设**
   - 建立内容社区
   - 提供专业服务支持
   - 推动行业标准制定

## 总结

Personal NotebookLM 项目展现了现代 AI 驱动知识管理系统的完整实现。通过精心设计的技术架构和优化的算法实现，项目在功能完整性、性能表现和用户体验方面都达到了较高水准。

项目的成功关键在于：

1. **架构设计**：清晰的分层架构和模块化设计
2. **性能优化**：针对向量检索和批量处理的专门优化
3. **用户体验**：直观的界面设计和流畅的交互体验
4. **技术选型**：合理的技术栈选择和工具集成

随着项目的持续发展，预计将不断完善功能特性，提升性能表现，并扩展应用场景，为用户提供更加智能化的知识管理解决方案。