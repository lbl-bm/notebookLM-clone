# M3 里程碑：事实校验与评测治理闭环

> 当前状态（2026-02）：暂缓执行。当前阶段人力优先投入 M1/M2，M3 作为后续规划保留。

## 1. 里程碑定位

### 1.1 目标

M3 的核心是把系统从“可控 RAG”升级为“可治理知识系统”：

- 对答案中的事实进行自动校验。
- 建立离线评测 + 在线监控 + 灰度回滚的质量闭环。
- 让模型升级、策略变更具备可量化收益判断。

### 1.2 范围边界

- **纳入**：claim 抽取、证据对齐校验、数值一致性校验、评测平台与发布门禁。
- **不纳入**：领域专用知识图谱深度建设（可作为后续专项）。

### 1.3 成功标准（摘要）

- 事实错误率显著下降。
- 版本发布具备自动评测门禁。
- 线上问题可通过闭环机制快速定位与修复。

---

## 2. 架构改造概览

### 2.1 改造前问题

- 生成结果虽受证据约束，但仍可能出现“引用正确、结论偏差”。
- 缺少 claim 级别自动校验与纠正流程。
- 优化迭代缺乏标准化回归门禁，容易“局部变好、全局变差”。

### 2.2 改造后链路

1. 生成完成后进入 Claim Extractor（抽取事实陈述）。
2. Claim Verifier 对每条 claim 做：
   - 证据存在性验证
   - 数值一致性验证
   - 实体关系一致性验证
3. 校验未通过的 claim 进入 Repair/Rephrase 子流程。
4. 输出最终答案 + 质量标签（validated / partial / uncertain）。
5. 全量写入评测与线上质量仓，支持版本对比。

---

## 3. 模块文件改造清单

## 3.1 `lib/rag` 目录新增治理模块

### 目标

在 RAG 层新增“后验校验与修复”能力。

### 建议新增文件

- `lib/rag/claim-extractor.ts`
- `lib/rag/claim-verifier.ts`
- `lib/rag/answer-repair.ts`
- `lib/rag/quality-gate.ts`

### 职责说明

- claim-extractor：将答案拆解为可验证声明。
- claim-verifier：逐条对照 citations 与证据文本进行核验。
- answer-repair：对失败声明进行重写、降级或删除。
- quality-gate：决定最终输出状态与发布动作。

## 3.2 `app/api/chat/route.ts`

### 目标

将“生成后校验”纳入主链路，并支持可控开销。

### 变更点

- 增加 post-generation validate 阶段。
- 支持阈值控制：仅对高风险问题或高价值场景启用完整校验。
- 输出 answerQualityStatus 与 verificationSummary。
- 对失败答案执行自动修复或谨慎降级。

### 注意

- 需配置严格超时，避免生成后校验无限膨胀。
- 校验失败不应阻塞系统响应，应优先返回可解释结果。

## 3.3 `lib/studio/generator.ts`

### 目标

让 Studio 产物同样具备质量标签。

### 变更点

- 对 summary / outline 进行 claim 抽样校验。
- 对 quiz / mindmap 进行结构合法性与事实一致性检查。
- 在 Artifact 元数据中写入质量标签与校验摘要。

### 注意

- 保持既有输出格式兼容。
- 失败策略优先“部分可用 + 不确定说明”。

## 3.4 `prisma/schema.prisma` 与 `prisma/migrations/*`

### 目标

提供评测与质量治理的持久化基础。

### 建议新增表（逻辑层）

- `evaluation_runs`：一次评测任务
- `evaluation_cases`：评测样本与标签
- `evaluation_results`：样本级指标结果
- `quality_incidents`：线上质量事故记录

### 说明

- 这些表建议通过 Prisma 模型 + SQL 索引共同管理。
- 关键查询维度需有索引支持（版本、模型、策略、日期）。

## 3.5 `scripts/*` 新增评测与回归脚本

### 建议新增文件

- `scripts/run-rag-evaluation.ts`
- `scripts/generate-eval-report.ts`
- `scripts/replay-production-queries.ts`

### 职责说明

- run-rag-evaluation：执行离线评测集。
- generate-eval-report：输出多维指标报告。
- replay-production-queries：回放线上匿名样本，验证版本回归。

## 3.6 `lib/config.ts`

### 建议新增配置项

- `RAG_CLAIM_VERIFICATION_ENABLED`
- `RAG_CLAIM_VERIFICATION_MODE`（strict / standard / off）
- `RAG_ANSWER_REPAIR_ENABLED`
- `RAG_EVAL_GATE_MIN_SCORE`
- `RAG_RELEASE_CANARY_PERCENT`
- `RAG_RELEASE_AUTO_ROLLBACK_ENABLED`

---

## 4. 评测体系设计

### 4.1 离线评测集分层

- 通用事实问答集：验证基础正确性。
- 复杂推理问答集：验证多证据整合。
- 长文档问答集：验证上下文预算与稳定性。
- 拒答场景集：验证不确定与无依据处理。

### 4.2 指标体系

- 检索层：Recall@K、nDCG、Evidence Coverage。
- 生成层：Citation Precision、Claim Accuracy、Numeric Consistency。
- 系统层：P95 时延、每问成本、成功率、回滚率。
- 产品层：采纳率、追问率、人工纠错率。

### 4.3 发布门禁

- 每次策略或模型升级前，必须跑离线评测。
- 关键指标低于阈值则阻断发布。
- 灰度期间持续监控线上指标，触发自动回滚规则。

---

## 5. 接口与契约（不写代码，定义行为）

### 5.1 校验结果契约

每次回答应产出内部校验摘要：

- claim 总数
- 通过数 / 失败数
- 失败类型分布
- 最终质量状态

### 5.2 修复策略契约

- 可修复：重写后再次校验。
- 不可修复：删除该结论并声明不确定。
- 高风险：直接降级为保守回答。

### 5.3 评测任务契约

- 输入：策略版本、模型版本、评测集版本。
- 输出：多维指标、与基线差异、是否通过门禁。

---

## 6. 验收标准（详细）

### 6.1 功能验收

- 能对答案进行 claim 级校验并输出摘要。
- 校验失败可触发自动修复或降级。
- Studio 产物具备质量标签。

### 6.2 质量验收

- 事实错误率、数字错误率显著下降。
- 拒答准确率与不确定声明准确率提升。
- 回归测试可稳定识别质量倒退。

### 6.3 性能验收

- 校验步骤开销在预算内。
- 可通过策略模式对高成本路径进行控制。
- 灰度阶段无明显性能抖动。

### 6.4 运营验收

- 有统一评测报告模板。
- 有可执行发布门禁规则。
- 有自动告警与回滚机制。

---

## 7. 实施计划（建议 4 周）

### 周 1

- 搭建 claim 抽取与校验骨架。
- 定义失败类型与修复策略分类。

### 周 2

- 接入 Chat 与 Studio 后处理链路。
- 打通质量标签写入。

### 周 3

- 建立离线评测集与自动评测脚本。
- 产出首版评测报告。

### 周 4

- 接入发布门禁与灰度监控。
- 完成自动回滚联调与演练。

---

## 8. 风险与回滚

### 8.1 主要风险

- 校验策略过严导致可用性下降。
- 自动修复可能引入二次偏差。
- 评测集覆盖不足导致误判上线质量。

### 8.2 回滚策略

- 关闭 claim 校验，保留 M2 链路。
- 关闭自动修复，仅输出校验提醒。
- 发布门禁故障时退回人工审核流程。

---

## 9. 里程碑完成定义（DoD）

- 系统具备 claim 级校验、修复与质量标注能力。
- 具备标准化离线评测与发布门禁流程。
- 模型/策略迭代从“经验驱动”转为“数据驱动”。
